{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text based method.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6gkwVXmhi1A"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from collections import Counter\n",
        "from gensim import corpora\n",
        "from statistics import mean\n",
        "import gensim\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import matplotlib as mpl \n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#File import"
      ],
      "metadata": {
        "id": "PqRrcZoRimbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the files s2013 and s2020 are available here: https://drive.google.com/drive/folders/1wkQN4_byG8uVf6AduA8nsC3QHN5ZOXH6?usp=sharing\n",
        "import csv\n",
        "filepath = './s2013.csv'\n",
        "s2013 = pd.read_csv(filepath,engine='python')\n",
        "filepath_2 = './s2020.csv'\n",
        "s2020 = pd.read_csv(filepath_2,engine='python',error_bad_lines=False)"
      ],
      "metadata": {
        "id": "e641IxEWig8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Construct features"
      ],
      "metadata": {
        "id": "kkaj-lNaiwFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#text vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words = None, ngram_range = (1,3)).fit(s2013['ABSTRACT'].values.astype('U'))\n",
        "vectorizer2 = TfidfVectorizer(stop_words = None, ngram_range = (1,3)).fit(s2013['TITLE'].values.astype('U'))"
      ],
      "metadata": {
        "id": "e53APREyiynD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct sparse feature matrix\n",
        "# params:\n",
        "#     df: dataframe, with 'original' and 'edit' columns\n",
        "#     vectorizer: sklearn text vectorizer, either TfidfVectorizer or Countvectorizer \n",
        "# return:\n",
        "#     M: a sparse feature matrix that represents df's textual information (used by a predictive model)\n",
        "\n",
        "def construct_feature_matrix(df, vectorizer, vectorizer2):\n",
        "    abstract = df['ABSTRACT'].apply(lambda x: np.str_(x)).tolist()\n",
        "    title = df['TITLE'].apply(lambda x: np.str_(x)).tolist()\n",
        "  \n",
        "    # here the dimensionality of X is len(df) x |V|\n",
        "    X = vectorizer.transform(abstract)\n",
        "    Y = vectorizer2.transform(title)\n",
        "    Z = scipy.sparse.hstack([X,Y])\n",
        "   \n",
        "    return Z"
      ],
      "metadata": {
        "id": "Xi5Wql87i1Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_Y = s2013['CITED']\n",
        "train_X = construct_feature_matrix(s2013, vectorizer,vectorizer2)\n",
        "print(train_X.shape)\n",
        "test_X = construct_feature_matrix(s2020, vectorizer, vectorizer2)\n",
        "print(test_X.shape)"
      ],
      "metadata": {
        "id": "2l7aiqk8i3Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Apply logistic regression and train"
      ],
      "metadata": {
        "id": "Bqs6hZ0Yi7NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='l2',class_weight = 'balanced').fit(train_X, train_Y)\n",
        "test_Y_hat = model.predict_proba(test_X)"
      ],
      "metadata": {
        "id": "MS5NgJ0GjCx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob=[]\n",
        "for i in range(0,len(test_Y_hat)):\n",
        "  prob.append(test_Y_hat[i][1])"
      ],
      "metadata": {
        "id": "j-4ejPFpjE16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a function to merge lists\n",
        "def merge(list1, list2, list3, list4):\n",
        "    merged_list = []\n",
        "    for i in range(max((len(list1), len(list2),len(list3),len(list4)))):\n",
        "      tup = (list1[i], list2[i], list3[i],list4[i])\n",
        "      merged_list.append(tup)\n",
        "    return merged_list"
      ],
      "metadata": {
        "id": "Hnciod9ajGRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create list of tuples and sort\n",
        "merged_list = merge(s2020['REFERENCE_ID'],s2020['PMID'],s2020['CITED'],prob)\n",
        "merged_list.sort(key=lambda y: y[3],reverse=True)"
      ],
      "metadata": {
        "id": "98EIWPPnjKtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculate Recall"
      ],
      "metadata": {
        "id": "OwhTr3MyjLZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_recall(filepath,pmid_only,num):\n",
        "  #parameters: filepath is the list computed above; \n",
        "  #       pmid_only limites whether the calculation only includes articles with PMIDs\n",
        "  #       num is the number of articles to go through for each calculation e.g: num = 1000 means that we want to calculate the recall every 1000 articles\n",
        "  pair = []\n",
        "  filepath.sort(key=lambda y: y[3],reverse=True)\n",
        "  if pmid_only == True:\n",
        "    filepath=list(filter(lambda c: np.isnan(c[1]) == False, filepath))\n",
        "  for i in range(1,len(filepath),num):\n",
        "    tp = 0\n",
        "    fn = 0\n",
        "    for j in range(1,i):\n",
        "      if filepath[j][2] == 1:\n",
        "        tp += 1\n",
        "    for k in range(i+1,len(filepath)):\n",
        "      if filepath[k][2] == 1:\n",
        "        fn += 1\n",
        "    pair.append((i,tp/(tp+fn)))\n",
        "  return pair"
      ],
      "metadata": {
        "id": "9w9iVnIZjPl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = 1000\n",
        "recall=calculate_recall(merged_list,True,num)\n",
        "recall"
      ],
      "metadata": {
        "id": "uo1x1slpjQVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualization"
      ],
      "metadata": {
        "id": "-1T-UVH2jS13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_axis = []\n",
        "y_axis = []\n",
        "for i in range(0,len(recall)):\n",
        "  x_axis.append(recall[i][0])\n",
        "  y_axis.append(recall[i][1])"
      ],
      "metadata": {
        "id": "Mz2CvBwsjVjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [i for i in range(len(y_axis)) if y_axis[i] > 0.95]\n",
        "initial=x[0]/len(y_axis)\n",
        "initial"
      ],
      "metadata": {
        "id": "qEGXMVgejYdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the percentile of articles going through when recall reaches 95% and 90%\n",
        "x = [i for i in range(len(y_axis)) if y_axis[i] > 0.95]\n",
        "per_95=x[0]*num\n",
        "y = [i for i in range(len(y_axis)) if y_axis[i] > 0.90]\n",
        "per_90=y[0]*num"
      ],
      "metadata": {
        "id": "pU7Anw2PjZ7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make a plot\n",
        "figure = plt.figure() \n",
        "axes1 = figure.add_subplot(1,1,1)  \n",
        "axes1.plot(x_axis,y_axis) \n",
        "plt.scatter([per_95],[0.95],s=25,c='r') \n",
        "plt.plot([0,per_95],[0.95,0.95],c='b',linestyle='--')\n",
        "plt.plot([per_95,per_95],[0,0.95],c='b',linestyle='--')\n",
        "plt.text(per_95+0.15,0.95-0.12,'recall@k=95%',ha='center',va='bottom',fontsize=10.5)\n",
        "plt.scatter([per_90],[0.90],s=25,c='r') \n",
        "plt.plot([0,per_90],[0.90,0.90],c='b',linestyle='--')\n",
        "plt.plot([per_90,per_90],[0,0.90],c='b',linestyle='--')\n",
        "plt.text(per_90+0.15,0.90-0.12,'recall@k=90%',ha='center',va='bottom',fontsize=10.5)\n",
        "ax = plt.gca()\n",
        "ax.spines['top'].set_color('none')\n",
        "ax.spines['right'].set_color('none')\n",
        "ax.xaxis.set_ticks_position('bottom')\n",
        "ax.yaxis.set_ticks_position('left')\n",
        "ax.spines['bottom'].set_position(('data',0))\n",
        "ax.spines['left'].set_position(('data',0))\n",
        "figure.show()"
      ],
      "metadata": {
        "id": "tUklBsbWir4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Active Learning"
      ],
      "metadata": {
        "id": "q9jvH7f2j0L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n=100\n",
        "iter=20\n",
        "index_list=[0]\n",
        "percentile_list=[initial]\n",
        "for j in range(1,iter):\n",
        "  uncertain=[]\n",
        "  for i in range(0,len(merged_list)):\n",
        "    if 0.45 <= merged_list[i][3] <= 0.55:\n",
        "      uncertain.append(merged_list[i][0])\n",
        "  uncertain_sampled = random.sample(uncertain,n)\n",
        "\n",
        "  for i in range(1,len(uncertain_sampled)):\n",
        "    for j in range(1,len(s2020)):\n",
        "      if s2020['REFERENCE_ID'][j] == uncertain_sampled[i]:\n",
        "        s2013=s2013.append(s2020.iloc[j])\n",
        "\n",
        "  vectorizer = TfidfVectorizer(stop_words = None, ngram_range = (1,3)).fit(s2013['ABSTRACT'].values.astype('U'))\n",
        "  vectorizer2 = TfidfVectorizer(stop_words = None, ngram_range = (1,3)).fit(s2013['TITLE'].values.astype('U'))\n",
        "\n",
        "  train_Y = s2013['CITED']\n",
        "  train_X = construct_feature_matrix(s2013, vectorizer,vectorizer2)\n",
        "  test_X = construct_feature_matrix(s2020, vectorizer, vectorizer2)\n",
        "\n",
        "\n",
        "  model = LogisticRegression(penalty='l2',class_weight = 'balanced').fit(train_X, train_Y)\n",
        "  test_Y_hat = model.predict_proba(test_X)\n",
        "\n",
        "  prob=[]\n",
        "  # index=[]\n",
        "  for i in range(0,len(test_Y_hat)):\n",
        "    prob.append(test_Y_hat[i][1])\n",
        "    # index.append(i)\n",
        "  merged_list=merge(s2020['REFERENCE_ID'],s2020['PMID'],s2020['CITED'],prob)\n",
        "  merged_list.sort(key=lambda y: y[3],reverse=True)\n",
        "  # merged_list = merge(index,prob,s2020['CITED'])\n",
        "  # merged_list.sort(key=lambda y: y[1],reverse=True)\n",
        "\n",
        "  recall=calculate_recall(merged_list,False,1000)\n",
        "  x_axis = []\n",
        "  y_axis = []\n",
        "  for i in range(0,len(recall)):\n",
        "    x_axis.append(recall[i][0])\n",
        "    y_axis.append(recall[i][1])\n",
        "\n",
        "  x = [i for i in range(len(y_axis)) if y_axis[i] > 0.95]\n",
        "  percentile=x[0]/len(y_axis)\n",
        "  percentile_list.append(percentile)\n",
        "  index_list.append(j*n)"
      ],
      "metadata": {
        "id": "RydeS1a7k1HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_list"
      ],
      "metadata": {
        "id": "Hlr2Zu3-kwY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}