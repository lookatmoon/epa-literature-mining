# -*- coding: utf-8 -*-
"""active learning with knowledge transfer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lITUw_I5iQ6m_PGU7ZniiLImZU_23nuv
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb

from collections import Counter
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from gensim import corpora
from statistics import mean
import gensim
import scipy
import random

import sklearn
from sklearn.linear_model import Ridge,SGDRegressor,LinearRegression
from sklearn.metrics import recall_score
from sklearn.feature_extraction.text import TfidfVectorchangizer, CountVectorizer, HashingVectorizer
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LogisticRegression

#the file combined_with_pseudo_label are available here: https://drive.google.com/drive/folders/1wkQN4_byG8uVf6AduA8nsC3QHN5ZOXH6?usp=sharing
combined_df = pd.read_csv("combined_with_pseudo_label.csv",engine='python',encoding='utf-8', error_bad_lines=False)

len(combined_df)

def get_title_and_abstract(df):
    corpus = []
    for index, row in df.iterrows():
        title = row['TITLE']
        abstract = row['ABSTRACT']
        corpus.append( str(title) + ' ' + str(abstract))
    return corpus

title_and_abstract = get_title_and_abstract(combined_df)

len(title_and_abstract)

vectorizer = TfidfVectorizer(stop_words = None, ngram_range = (1,1)).fit(title_and_abstract)

# construct sparse feature matrix
# params:
#     df: dataframe, with 'ABSTRACT' and 'TITLE' columns
#     vectorizer: sklearn text vectorizer, either TfidfVectorizer or Countvectorizer 
# return:
#     M: a sparse feature matrix that represents df's textual information (used by a predictive model)

def construct_feature_matrix(df, vectorizer):
    abstract = df['ABSTRACT'].apply(lambda x: np.str_(x)).tolist()
    title = df['TITLE'].apply(lambda x: np.str_(x)).tolist()
  
    # here the dimensionality of X is len(df) x |V|
    X = vectorizer.transform(abstract)
    Y = vectorizer.transform(title)
    Z = scipy.sparse.hstack([X,Y])
    
    return Z

train_Y = combined_df['fake_label']
train_X = construct_feature_matrix(combined_df, vectorizer)
test_X = construct_feature_matrix(combined_df, vectorizer)
print(train_X.shape)
print(test_X.shape)

model = LogisticRegression(penalty='l2', class_weight = 'balanced').fit(train_X, train_Y)
test_Y_hat = model.predict_proba(test_X)

prob=[]
# index=[]
for i in range(0,len(test_Y_hat)):
  prob.append(test_Y_hat[i][1])

combined_df['lr_score'] = pd.Series(prob).reset_index(drop=True)

combined_df = combined_df.sort_values(by='lr_score', ascending=False,ignore_index = True)
combined_df

def calculate_recall(filepath,pmid_only,num):
  #when filepath is a data frame
  pair = []  
  if pmid_only == True:
    filepath=filepath.loc[filepath.PMID.notnull()]
    filepath=filepath.reset_index(drop=True)
  for i in range(1,len(filepath),num):
    tp = 0
    fn = 0
    for j in range(0,i):
      if filepath['Label'][j] == 1:
        tp += 1
    for k in range(i+1,len(filepath)):
      if filepath['Label'][k] == 1:
        fn += 1
    pair.append((i,tp/(tp+fn)))
  return pair

recall=calculate_recall(combined_df,False,1000)

x_axis = []
y_axis = []
for i in range(0,len(recall)):
  x_axis.append(recall[i][0])
  y_axis.append(recall[i][1])

x = [i for i in range(len(y_axis)) if y_axis[i] > 0.95]
initial_95=x[0]/len(y_axis)
y = [i for i in range(len(y_axis)) if y_axis[i] > 0.90]
initial_90=y[0]/len(y_axis)

initial_95

size = len(combined_df)

batch_size=100
iter=20
percentile_list_95=[initial_95]
percentile_list_90=[initial_90]

#create the added label to mark the uncertain articles during each iteration
added = [0 for i in range(len(combined_df))]
combined_df['added'] = pd.Series(added).reset_index(drop=True)

for j in range(0,iter):
  #sort by lr_score
  combined_df = combined_df.sort_values(by='lr_score', ascending=False,ignore_index = True)

  #sample 100 uncertain cases; label them as added
  heroid_uncertain = []
  label_uncertain = []

  #initialize weight vector
  w = [0.01 for i in range(len(combined_df))]

  #random sample: randomly sample 100 articles and correct the label; increase the weight of added articles to 1
  #to do random sample: uncomment the section below and comment the learning section
  # ram = []
  # for i in range(0,batch_size):
  #   ram.append(random.randint(0,size))
  # for i in ram: 
  #   if combined_df['added'][i] != 1:
  #     heroid_uncertain.append(combined_df['HeroId'][i])
  #     label_uncertain.append(combined_df['Label'][i])
  #     combined_df['added'][i] = 1
  #     w[i] = 1

  #uncertain sample: sample 100 articles around 0.5 predicted score and correct the label; increase the weight of added articles to 1
  first = [i for i in range(len(combined_df)) if combined_df['lr_score'][i] < 0.5]
  position = first[0]
  for i in range(batch_size * iter): 
    if combined_df['added'][position+i] != 1:
      heroid_uncertain.append(combined_df['HeroId'][position+i])
      label_uncertain.append(combined_df['Label'][position+i])
      combined_df['added'][position+i] = 1
      w[i] = 1
    if len(heroid_uncertain)>batch_size:
      break  


  #create the dataframe for uncertain cases
  uncertain = pd.DataFrame(
      {'HeroId': heroid_uncertain,
      'Label': label_uncertain
      })


  #merge dataframe and update the fake_label column with the true values for 100 uncertain articles
  combined_df = pd.merge(combined_df, uncertain, on ='HeroId', how ='outer')
  for i in range(len(combined_df)):
    if combined_df['Label_y'][i] == 0 or combined_df['Label_y'][i] == 1:
      combined_df['fake_label'][i] = combined_df['Label_y'][i]
  combined_df.drop('Label_y', inplace=True, axis=1)
  combined_df.rename(columns={'Label_x':'Label'}, inplace = True)
  

  #train
  title_and_abstract = get_title_and_abstract(combined_df)
  vectorizer = TfidfVectorizer(stop_words = None, ngram_range = (1,1)).fit(title_and_abstract)
  train_Y = combined_df['fake_label']
  train_X = construct_feature_matrix(combined_df, vectorizer)
  test_X = construct_feature_matrix(combined_df, vectorizer)
  model = LogisticRegression(penalty='l2',class_weight = 'balanced').fit(train_X, train_Y,sample_weight=w)
  test_Y_hat = model.predict_proba(test_X)  
  
  prob=[]
  for i in range(0,len(test_Y_hat)):
    prob.append(test_Y_hat[i][1])
  combined_df['lr_score'] = pd.Series(prob).reset_index(drop=True)

  #sort
  combined_df = combined_df.sort_values(by='lr_score', ascending=False,ignore_index = True)

  #calculate recall
  recall=calculate_recall(combined_df,False,1000)
  x_axis = []
  y_axis = []
  for i in range(0,len(recall)):
    x_axis.append(recall[i][0])
    y_axis.append(recall[i][1])

  x = [i for i in range(len(y_axis)) if y_axis[i] > 0.95]
  per_95=x[0]/len(y_axis)
  y = [i for i in range(len(y_axis)) if y_axis[i] > 0.90]
  per_90=y[0]/len(y_axis)

  percentile_list_95.append(per_95)
  percentile_list_90.append(per_90)

index_list=[]
for i in range(len(percentile_list_95)):
  a = 100*i
  index_list.append(a)

figure = plt.figure() 
axes1 = figure.add_subplot(1,1,1)  
axes1.plot(index_list,percentile_list_95) 
plt.title('Percentile when recall@k = 95%')
ax = plt.gca()
ax.spines['top'].set_color('none')
ax.spines['right'].set_color('none')
ax.xaxis.set_ticks_position('bottom')
ax.yaxis.set_ticks_position('left')
figure.show()

pl = pd.DataFrame(percentile_list_95) 
pl.to_csv('percentile_list_active_learning.csv')